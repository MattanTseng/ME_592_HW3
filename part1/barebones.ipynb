{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = './Combustion_data_ME592_Assignment/Aditya_data/combustion_img_13.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m arrays \u001b[39m=\u001b[39m {}\n\u001b[0;32m      3\u001b[0m image_shape \u001b[39m=\u001b[39m (\u001b[39m250\u001b[39m, \u001b[39m100\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m data \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39;49mFile(data_path)\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     10\u001b[0m     arrays[k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(v)\n",
      "File \u001b[1;32mc:\\Users\\Matta\\Documents\\Python\\ME_592_HW3\\myenv\\lib\\site-packages\\h5py\\_hl\\files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    558\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    560\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[0;32m    561\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[0;32m    562\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[0;32m    563\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    564\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    565\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    566\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 567\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\Matta\\Documents\\Python\\ME_592_HW3\\myenv\\lib\\site-packages\\h5py\\_hl\\files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[0;32m    230\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 231\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[0;32m    232\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    233\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = './Combustion_data_ME592_Assignment/Aditya_data/combustion_img_13.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "data_path = \"./Combustion_data_ME592_Assignment/Aditya_data/combustion_img_13.mat\"\n",
    "arrays = {}\n",
    "image_shape = (250, 100)\n",
    "\n",
    "\n",
    "\n",
    "data = h5py.File(data_path)\n",
    "\n",
    "for k, v in data.items():\n",
    "    arrays[k] = np.array(v)\n",
    "\n",
    "train_set_x = arrays[\"train_set_x\"]\n",
    "train_set_y = arrays[\"train_set_y\"]\n",
    "\n",
    "print(\"The shape of train x: \", train_set_x.shape)\n",
    "print(\"The shape of train y: \", train_set_y.shape)\n",
    "train_images = rearrange(train_set_x, \"(y h) (x w) -> (y x) h w\", w = image_shape[0], h = image_shape[1])\n",
    "\n",
    "print(\"shape of train array: \", train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "# now that our data preparation is complete, we can start setting up our CNN\n",
    "# Input: Image\n",
    "# Output: Stable/Unstable (1 or 0)\n",
    "\n",
    "# these are the hyperparameters for the model\n",
    "# remember that a batch is how many items the  model will train on before updating the model\n",
    "batch_size = 4\n",
    "# remember that an epoch is the number of times that the trainer will go through the entire dataset\n",
    "epochs = 1 \n",
    "# since our image is rectangular, let's use a rectangular kernel. \n",
    "# this touple is comprised of factors of the dimensions. \n",
    "kernel_size = (25, 10) \n",
    "input_height = train_images[0].shape[0]\n",
    "input_width = train_images[0].shape[1]\n",
    "\n",
    "\n",
    "stride = 1\n",
    "classes = (\"stable\", \"unstable\")\n",
    "number_channels = 1 # this is a grayscale image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# to increase the speed of the training, make sure that the GPU is being used. \n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "print(\"Number of epochs: \", epochs)\n",
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Kernel size: \", kernel_size)\n",
    "print(\"Stride size: \", stride)\n",
    "print(\"Classes: \", classes)\n",
    "print(\"input height: \", input_height)\n",
    "print(\"input width: \", input_width)\n",
    "print(\"device type: \", device)\n",
    "# print(\"The device being used is: \", device)\n",
    "\n",
    "# These links were used for reference \n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/\n",
    "# for a test, let's train this first without using the validation set. \n",
    "# that way we can prove that the validation set actually does help increase accuracy and decrease overfitting\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # self.fc1 = nn.Linear(800, 64)\n",
    "        self.fc1 = nn.Linear(89792, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "\n",
    "        # num_flat_features = x.size(1)*x.size(2)*x.size(3)\n",
    "        # x = x.view(-1, num_flat_features)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to convert our numpy arrays into pytorch tensors\n",
    "batch_size = 16\n",
    "train_images_torch = torch.div(torch.from_numpy(train_images).float(), 255)\n",
    "print(\"train_images.size: \", train_images_torch.size)\n",
    "\n",
    "train_labels_torch = torch.from_numpy(train_set_y).float()\n",
    "print(\"shape of labels: \", len(train_labels_torch))\n",
    "\n",
    "train_loader = torch.utils.data.TensorDataset(train_images_torch, train_labels_torch)\n",
    "train_loader = torch.utils.data.DataLoader(train_loader, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "\n",
    "cnn = CNN()\n",
    "cnn.to(device)\n",
    "print(cnn)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch number: \", epoch)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "    # for some initial testing, I used the validation set because it is smaller.\n",
    "    # for i, data in enumerate(val_loader, 0): \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        inputs = rearrange(inputs, \"(c b) h w -> b c h w\", c = 1)\n",
    "        # print(\"shape of inputs: \", inputs.shape)\n",
    "        # print(\"shape of labels: \", labels.shape)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn(inputs)\n",
    "\n",
    "        # print(\"shape of outputs: \", outputs.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            # print(\"shape of inputs: \", inputs.shape)\n",
    "            # print(\"shape of outputs: \", outputs.shape)\n",
    "            # print(\"Here are the outputs: \", outputs)\n",
    "            print(f'[epoch: {epoch + 1}, batch: {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            losses.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "train_time = end_time - start_time\n",
    "\n",
    "print(\"Elapsed Training Time: \", datetime.timedelta(seconds = train_time))\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
