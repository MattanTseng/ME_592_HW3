{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bf3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transformers\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d149de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53999, 1024)\n",
      "(53999, 1)\n"
     ]
    }
   ],
   "source": [
    "train_codes = pd.read_csv('train_embbeds.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "print(train_codes.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f6a12f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53999, 1024)\n",
      "(53999, 1)\n"
     ]
    }
   ],
   "source": [
    "train_set = train_codes.iloc[:,0:1024].values\n",
    "train_set_labels= train_labels.iloc[:,:].values\n",
    "print(train_set.shape)\n",
    "print(train_set_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438dc7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17999, 1024)\n",
      "(17999, 1)\n"
     ]
    }
   ],
   "source": [
    "test_codes = pd.read_csv('test_embbeds.csv')\n",
    "test_labels = pd.read_csv('test_labels.csv')\n",
    "print(test_codes.shape)\n",
    "print(test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e124fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17999, 1024)\n",
      "(17999, 1)\n"
     ]
    }
   ],
   "source": [
    "test_set = test_codes.iloc[:,0:1024].values\n",
    "test_set_labels= test_labels.iloc[:,:].values\n",
    "print(test_set.shape)\n",
    "print(test_set_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95184256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(dataX,dataY, seq_length):\n",
    "    print(\"shape of data: \", dataX.shape)\n",
    "    print(\"shape of data labels: \", dataY.shape)\n",
    "    print(\"seq_length: \", seq_length)\n",
    "    \n",
    "    #batch_len=len(dataX)\n",
    "    \n",
    "    #x = torch.empty((1,4,1024))\n",
    "    # y = torch.empty((1,1))\n",
    "    #y = torch.empty(1,1)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(len(dataX)-seq_length-1):\n",
    "        _x = dataX[i:(i+seq_length)]\n",
    "        _y = dataY[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "    \n",
    "    #for i in range(batch_len-seq_length-1):\n",
    "        # _x = data.detach()[i:(i+seq_length)]\n",
    "        # _y = data.detach()[i+seq_length]\n",
    "        #_x = dataX[i:(i+seq_length)]\n",
    "        #_y = dataY[i+seq_length]\n",
    "        \n",
    "        #_xOut=rearrange(_x,'w h -> 1 w h')\n",
    "        #_yOut=rearrange(_y,'w -> 1 w')\n",
    "\n",
    "\n",
    "        #x = torch.cat((x, _xOut),dim=0)\n",
    "        #y = torch.cat((y, _yOut),dim=0)\n",
    "\n",
    "    # return torch.tensor(x),torch.tensor(y)\n",
    "    #print(\"Size of x: \", x.size())\n",
    "    #print(\"Size of _x: \", _x.size())\n",
    "    #print(\"Size of y: \", y.size())\n",
    "    #print(\"Size of _y: \", _y.size())\n",
    "    \n",
    "    x_array=np.array(x)\n",
    "    y_array=np.array(y)\n",
    "    \n",
    "    return torch.tensor(x_array), torch.tensor(y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0225a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (53999, 1024)\n",
      "shape of data labels:  (53999, 1)\n",
      "seq_length:  3\n",
      "The shape of x_train:  torch.Size([53995, 3, 1024])\n",
      "The length of x_train:  53995\n",
      "The shape of y_train:  torch.Size([53995, 1])\n",
      "The length of y_train:  53995\n"
     ]
    }
   ],
   "source": [
    "seq_length = 3\n",
    "x_train, y_train = sliding_windows(train_set, train_set_labels, seq_length)\n",
    "\n",
    "print(\"The shape of x_train: \", x_train.size())\n",
    "print(\"The length of x_train: \", len(x_train))\n",
    "print(\"The shape of y_train: \", y_train.size())\n",
    "print(\"The length of y_train: \", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e37f5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.float()\n",
    "y_train=y_train.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce23fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, device):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size)).to(device)\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size)).to(device)\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d22f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec88e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainX:  torch.Size([53995, 3, 1024])\n",
      "Shape of trainY:  torch.Size([53995, 1])\n"
     ]
    }
   ],
   "source": [
    "trainX = Variable(x_train)\n",
    "trainY = Variable(y_train)\n",
    "    \n",
    "print(\"Shape of trainX: \", trainX.size())\n",
    "print(\"Shape of trainY: \", trainY.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295458ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  3150337\n",
      "Epoch: 0, loss: 0.45414\n",
      "Epoch: 2, loss: 0.19673\n",
      "Epoch: 4, loss: 0.12023\n",
      "Epoch: 6, loss: 0.13009\n",
      "Epoch: 8, loss: 0.07631\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 1024\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "# locate our GPU device and initialize it for training\n",
    "#use_cuda = torch.cuda.is_available()\n",
    "#device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers, device)\n",
    "lstm.to(device)\n",
    "print(\"Number of parameters: \", sum(p.numel() for p in lstm.parameters()))\n",
    "\n",
    "criterion = torch.nn.MSELoss()    # mean-sqaured error for regression\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(trainX.to(device))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY.to(device))\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353d6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me592",
   "language": "python",
   "name": "me592"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
